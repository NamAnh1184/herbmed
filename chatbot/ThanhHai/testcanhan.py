import streamlit as st
import json
import os
import pickle
from datetime import datetime
import re
import unicodedata

# ===== PAGE CONFIG =====
st.set_page_config(
    page_title="Medical Chatbot ğŸ¥",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== CUSTOM CSS =====
st.markdown("""
<style>
    .stChatMessage {
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 1rem;
    }
    .main-header {
        text-align: center;
        padding: 2rem 0;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .stats-card {
        background-color: #ffffff;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
    }
    .warning-box {
        background-color: #fff3cd;
        border-left: 4px solid #ffc107;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ===== INITIALIZE SESSION STATE =====
def init_session_state():
    """Khá»Ÿi táº¡o session state"""
    if 'chatbot' not in st.session_state:
        st.session_state.chatbot = None
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'model_loaded' not in st.session_state:
        st.session_state.model_loaded = False
    if 'show_sources' not in st.session_state:
        st.session_state.show_sources = True
    if 'show_intent' not in st.session_state:
        st.session_state.show_intent = True
    if 'data_stats' not in st.session_state:
        st.session_state.data_stats = {}

init_session_state()

# ============================================================
# 0) HELLO RULE (KHÃ”NG DÃ™NG API)
# ============================================================
HELLO_PATTERNS = [
    r"^\s*(hi|hello|hey|helo|hii+)\s*$",
    r"^\s*(xin\s*chÃ o|chÃ o|chao|chÃ o\s*báº¡n|chao\s*ban)\s*$",
    r"^\s*(alo|a\s*l\s*o|Ãª|Ãªi|ei|ad\s*Æ¡i|admin\s*Æ¡i|mÃ y\s*Æ¡i|may\s*oi)\s*$",
    r"^\s*(chÃ o\s*buá»•i\s*sÃ¡ng|chÃ o\s*buá»•i\s*trÆ°a|chÃ o\s*buá»•i\s*chiá»u|chÃ o\s*buá»•i\s*tá»‘i)\s*$",
]
HELLO_REPLY = (
    "Xin chÃ o ğŸ‘‹ MÃ¬nh lÃ  **trá»£ lÃ½ áº£o tÆ° váº¥n thÃ´ng tin bá»‡nh tiÃªu hoÃ¡**.\n\n"
    "Báº¡n cÃ³ thá»ƒ há»i theo cÃ¡c dáº¡ng:\n"
    "- **Triá»‡u chá»©ng**: â€œÄ‘au bá»¥ng, buá»“n nÃ´n lÃ  bá»‡nh gÃ¬?â€\n"
    "- **Bá»‡nh**: â€œtriá»‡u chá»©ng viÃªm dáº¡ dÃ y?â€\n"
    "- **Thuá»‘c**: â€œomeprazole dÃ¹ng nhÆ° tháº¿ nÃ o?â€\n"
    "- **Tháº£o dÆ°á»£c**: â€œnghá»‡ vÃ ng cÃ³ tÃ¡c dá»¥ng gÃ¬?â€\n\n"
    "âš ï¸ ThÃ´ng tin chá»‰ mang tÃ­nh tham kháº£o, khÃ´ng thay tháº¿ tÆ° váº¥n bÃ¡c sÄ©."
)

def hello_no_api_reply(user_query: str):
    q = user_query.strip().lower()
    for pat in HELLO_PATTERNS:
        if re.search(pat, q, flags=re.IGNORECASE):
            return {
                "query": user_query,
                "intent": "smalltalk",
                "response": HELLO_REPLY,
                "retrieved_docs": []
            }
    return None

# ============================================================
# 1) LOAD SYNONYMS.JSON (giá»¯ nguyÃªn luá»“ng cÃ²n láº¡i)
# ============================================================
def _remove_accents(s: str) -> str:
    s = unicodedata.normalize("NFD", s)
    s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")
    return unicodedata.normalize("NFC", s)

def _norm(s: str) -> str:
    s = s.strip().lower()
    s = _remove_accents(s)
    s = re.sub(r"\s+", " ", s)
    return s

@st.cache_data
def load_synonyms(path: str = "synonyms.json") -> dict:
    """
    Äá»c synonyms.json náº¿u cÃ³ (Ä‘áº·t cÃ¹ng thÆ° má»¥c vá»›i app.py).
    Tráº£ vá» dict: intent -> list[phrase_normalized]
    """
    if not os.path.exists(path):
        return {}
    try:
        with open(path, "r", encoding="utf-8") as f:
            raw = json.load(f)
        return {k: [_norm(x) for x in v] for k, v in raw.items() if isinstance(v, list)}
    except Exception:
        return {}

# ============================================================
# 2) LOAD CHATBOT FROM SAVED MODEL
# ============================================================
@st.cache_resource
def load_chatbot_from_saved_model(save_dir="./saved_model"):
    """
    Load chatbot tá»« saved model
    Sá»­ dá»¥ng @st.cache_resource Ä‘á»ƒ cache vÃ  trÃ¡nh load láº¡i nhiá»u láº§n
    """
    try:
        # Import OpenAI + dotenv (náº¿u cÃ³)
        try:
            from openai import OpenAI
        except Exception:
            return None, "Thiáº¿u thÆ° viá»‡n openai. HÃ£y cÃ i: pip install openai"

        try:
            from dotenv import load_dotenv
            load_dotenv()
        except Exception:
            # KhÃ´ng báº¯t buá»™c dotenv náº¿u báº¡n Ä‘Ã£ export OPENAI_API_KEY
            pass

        # Kiá»ƒm tra saved model cÃ³ tá»“n táº¡i khÃ´ng
        if not os.path.exists(save_dir):
            return None, "KhÃ´ng tÃ¬m tháº¥y saved model. Vui lÃ²ng cháº¡y file chatbot chÃ­nh trÆ°á»›c Ä‘á»ƒ táº¡o model."

        # Load metadata
        with open(os.path.join(save_dir, 'model_metadata.json'), 'r', encoding='utf-8') as f:
            metadata = json.load(f)

        # Load data
        with open(os.path.join(save_dir, 'data_loader.json'), 'r', encoding='utf-8') as f:
            data = json.load(f)

        # Load embeddings (há»— trá»£ nhiá»u tÃªn file)
        qa_candidates = [
            os.path.join(save_dir, 'qa_embeddings.pkl'),
            os.path.join(save_dir, 'qa_embbedings.pkl'),
            os.path.join(save_dir, 'qa_embbedings.pkl'),
        ]
        qa_file = next((p for p in qa_candidates if os.path.exists(p)), None)
        if not qa_file:
            return None, "KhÃ´ng tÃ¬m tháº¥y file QA embeddings (.pkl) trong saved_model."

        with open(qa_file, 'rb') as f:
            qa_embeddings = pickle.load(f)

        with open(os.path.join(save_dir, 'embedding_cache.pkl'), 'rb') as f:
            embedding_cache = pickle.load(f)

        # Táº¡o OpenAI client
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        # Táº¡o chatbot object
        chatbot = {
            'client': client,
            'data': data,
            'qa_embeddings': qa_embeddings,
            'embedding_cache': embedding_cache,
            'metadata': metadata,
            'qa_file': os.path.basename(qa_file),
        }

        return chatbot, None

    except Exception as e:
        return None, f"Lá»—i khi load model: {str(e)}"

# ============================================================
# 3) CHATBOT LOGIC FUNCTIONS (giá»¯ nguyÃªn, chá»‰ chá»‰nh intent Ä‘á»c synonyms.json)
# ============================================================
def get_embedding(client, text: str, embedding_cache: dict, model="text-embedding-3-small"):
    """Láº¥y embedding cho text"""
    if text in embedding_cache:
        return embedding_cache[text]

    text = text.replace("\n", " ").strip()
    response = client.embeddings.create(input=[text], model=model)
    embedding = response.data[0].embedding
    embedding_cache[text] = embedding
    return embedding

def compute_similarity(emb1, emb2):
    """TÃ­nh cosine similarity (Æ°u tiÃªn sklearn; náº¿u thiáº¿u sklearn thÃ¬ fallback thá»§ cÃ´ng)"""
    try:
        from sklearn.metrics.pairwise import cosine_similarity
        return cosine_similarity([emb1], [emb2])[0][0]
    except Exception:
        # fallback cosine thá»§ cÃ´ng
        dot = 0.0
        na = 0.0
        nb = 0.0
        for x, y in zip(emb1, emb2):
            dot += float(x) * float(y)
            na += float(x) * float(x)
            nb += float(y) * float(y)
        denom = (na ** 0.5) * (nb ** 0.5) + 1e-12
        return dot / denom

def classify_intent(client, query: str) -> str:
    """
    PhÃ¢n loáº¡i intent:
    - Æ¯u tiÃªn Ä‘á»c tá»« synonyms.json (náº¿u cÃ³)
    - Náº¿u khÃ´ng cÃ³ file, fallback vá» keyword list cÅ© cá»§a báº¡n
    """
    synonyms = load_synonyms("synonyms.json")
    qn = _norm(query)

    # Æ¯u tiÃªn symptom_to_disease trÆ°á»›c
    if synonyms:
        priority = ["symptom_to_disease", "interaction", "drug", "herb", "symptoms", "general"]
        for intent in priority:
            for phrase in synonyms.get(intent, []):
                if phrase and phrase in qn:
                    return intent

    # Fallback (giá»¯ nguyÃªn logic cÅ©)
    INTENTS = {
        "symptoms": ["triá»‡u chá»©ng", "dáº¥u hiá»‡u", "biá»ƒu hiá»‡n", "symptoms", "signs"],
        "herb": ["tháº£o dÆ°á»£c", "nghá»‡", "Ä‘Ã´ng y", "yhct", "herb", "herbal"],
        "drug": ["thuá»‘c tÃ¢y", "thuá»‘c", "drug", "medicine", "medication"],
        "interaction": ["tÆ°Æ¡ng tÃ¡c", "dÃ¹ng chung", "káº¿t há»£p", "interaction", "combine"],
        "symptom_to_disease": ["tÃ´i bá»‹", "tÃ´i cÃ³", "bá»‡nh gÃ¬", "what disease", "i have"],
        "general": ["lÃ  gÃ¬", "what is", "thÃ´ng tin", "information"]
    }

    query_lower = query.lower()
    for intent, keywords in INTENTS.items():
        for keyword in keywords:
            if keyword in query_lower:
                return intent

    return "general"

def retrieve_documents(client, query: str, intent: str, qa_embeddings: list,
                       embedding_cache: dict, top_k: int = 3):
    """Retrieve top-k relevant documents"""
    query_embedding = get_embedding(client, query, embedding_cache)

    scores = []
    for item in qa_embeddings:
        if intent != "general" and item["qa"].get("intent") != intent:
            continue

        similarity = compute_similarity(query_embedding, item["embedding"])
        scores.append((similarity, item["qa"]))

    scores.sort(reverse=True, key=lambda x: x[0])
    return [{"score": score, "qa": qa} for score, qa in scores[:top_k]]

def generate_response(client, query: str, intent: str, retrieved_docs: list) -> str:
    """Generate response tá»« retrieved documents"""

    if not retrieved_docs:
        return f"""Xin lá»—i, CSDL hiá»‡n táº¡i chÆ°a cÃ³ Ä‘á»§ thÃ´ng tin Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i: "{query}"

ğŸ’¡ Gá»£i Ã½:
- Thá»­ diá»…n Ä‘áº¡t cÃ¢u há»i khÃ¡c Ä‘i
- Cung cáº¥p thÃªm triá»‡u chá»©ng cá»¥ thá»ƒ
- NÃªu rÃµ tÃªn bá»‡nh hoáº·c thuá»‘c báº¡n muá»‘n há»i

âš ï¸ Náº¿u báº¡n cÃ³ triá»‡u chá»©ng nghiÃªm trá»ng, hÃ£y Ä‘áº¿n cÆ¡ sá»Ÿ y táº¿ Ä‘á»ƒ Ä‘Æ°á»£c thÄƒm khÃ¡m trá»±c tiáº¿p.
"""

    # Prepare context
    context_parts = []
    for i, doc in enumerate(retrieved_docs, 1):
        qa = doc["qa"]
        score = doc["score"]

        context_parts.append(f"""
[TÃ i liá»‡u {i}] (Äá»™ liÃªn quan: {score:.2f})
Bá»‡nh: {qa.get('disease', 'N/A')}
Intent: {qa.get('intent', 'N/A')}
CÃ¢u tráº£ lá»i tá»« CSDL:
{qa.get('answer', 'N/A')}
---
""")

    context = "\n".join(context_parts)

    system_prompt = """Báº¡n lÃ  trá»£ lÃ½ y táº¿ AI chuyÃªn nghiá»‡p, tráº£ lá»i HOÃ€N TOÃ€N dá»±a trÃªn dá»¯ liá»‡u cÃ³ sáºµn trong cÆ¡ sá»Ÿ dá»¯ liá»‡u (CSDL).

QUY Táº®C Báº®T BUá»˜C:
1. CHá»ˆ sá»­ dá»¥ng thÃ´ng tin tá»« CSDL Ä‘Æ°á»£c cung cáº¥p
2. KHÃ”NG bá»• sung kiáº¿n thá»©c y khoa bÃªn ngoÃ i
3. KHÃ”NG Ä‘Æ°a ra khuyáº¿n nghá»‹ Ä‘iá»u trá»‹ cá»¥ thá»ƒ
4. LuÃ´n nháº¯c nhá»Ÿ: "âš ï¸ ThÃ´ng tin mang tÃ­nh tham kháº£o, khÃ´ng thay tháº¿ cháº©n Ä‘oÃ¡n vÃ  tÆ° váº¥n y khoa trá»±c tiáº¿p"
5. Náº¿u CSDL khÃ´ng cÃ³ thÃ´ng tin, nÃ³i rÃµ "CSDL chÆ°a cÃ³ thÃ´ng tin vá»..."
6. TrÃ­ch dáº«n nguá»“n tá»« CSDL khi cÃ³
7. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, rÃµ rÃ ng, cÃ³ cáº¥u trÃºc

Äá»ŠNH Dáº NG TRáº¢ Lá»œI:
- Sá»­ dá»¥ng bullet points khi liá»‡t kÃª
- Highlight tá»« khÃ³a quan trá»ng báº±ng **bold**
- ThÃªm emoji phÃ¹ há»£p Ä‘á»ƒ dá»… Ä‘á»c
"""

    user_prompt = f"""CÃ¢u há»i: {query}

Intent: {intent}

ThÃ´ng tin tá»« CSDL:
{context}

HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a HOÃ€N TOÃ€N trÃªn thÃ´ng tin tá»« CSDL trÃªn."""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.3,
        max_tokens=1500
    )

    return response.choices[0].message.content

def chat_with_bot(chatbot, user_query: str):
    """Main chat function"""

    # âœ… 0) HELLO: tráº£ lá»i ngay, KHÃ”NG dÃ¹ng API
    rb = hello_no_api_reply(user_query)
    if rb is not None:
        return rb

    # pháº§n cÃ²n láº¡i giá»¯ nguyÃªn (cÃ³ API nhÆ° cÅ©)
    client = chatbot['client']
    qa_embeddings = chatbot['qa_embeddings']
    embedding_cache = chatbot['embedding_cache']

    # Classify intent (Ä‘á»c synonyms.json trÆ°á»›c)
    intent = classify_intent(client, user_query)

    # Retrieve documents
    retrieved_docs = retrieve_documents(
        client, user_query, intent, qa_embeddings, embedding_cache, top_k=3
    )

    # Generate response
    response = generate_response(client, user_query, intent, retrieved_docs)

    return {
        "query": user_query,
        "intent": intent,
        "response": response,
        "retrieved_docs": retrieved_docs
    }

# ===== HELPER FUNCTIONS =====
def get_intent_emoji(intent: str) -> str:
    """Láº¥y emoji cho tá»«ng intent"""
    intent_emojis = {
        "symptoms": "ğŸ©º",
        "herb": "ğŸŒ¿",
        "drug": "ğŸ’Š",
        "interaction": "âš ï¸",
        "symptom_to_disease": "ğŸ”",
        "general": "â„¹ï¸",
        "smalltalk": "ğŸ’¬",
    }
    return intent_emojis.get(intent, "ğŸ’¬")

def export_chat_history():
    """Export lá»‹ch sá»­ chat ra file JSON"""
    if st.session_state.chat_history:
        export_data = {
            "exported_at": datetime.now().isoformat(),
            "total_messages": len(st.session_state.chat_history),
            "chat_history": st.session_state.chat_history
        }
        json_str = json.dumps(export_data, ensure_ascii=False, indent=2)
        return json_str
    return None

# ============================================================
# SIDEBAR
# ============================================================
with st.sidebar:
    st.markdown("## âš™ï¸ CÃ i Ä‘áº·t")

    if not st.session_state.model_loaded:
        if st.button("ğŸš€ Khá»Ÿi Ä‘á»™ng Chatbot", use_container_width=True):
            with st.spinner("ğŸ”„ Äang táº£i Medical Chatbot..."):
                chatbot, error = load_chatbot_from_saved_model("./saved_model")

                if error:
                    st.error(f"âŒ {error}")
                    st.info("ğŸ’¡ **HÆ°á»›ng dáº«n:** Cháº¡y file chatbot chÃ­nh trÆ°á»›c Ä‘á»ƒ táº¡o saved model, sau Ä‘Ã³ quay láº¡i Ä‘Ã¢y.")
                else:
                    st.session_state.chatbot = chatbot
                    st.session_state.model_loaded = True
                    st.session_state.data_stats = {
                        'diseases': len(chatbot['data'].get('disease_names', {})),
                        'qa_pairs': len(chatbot['data'].get('qa_bank_flat', [])),
                        'embeddings': len(chatbot.get('embedding_cache', {})),
                        'qa_file': chatbot.get('qa_file', '')
                    }
                    st.success("âœ… Chatbot Ä‘Ã£ sáºµn sÃ ng!")
                    st.rerun()
    else:
        st.success("âœ… Chatbot Ä‘ang hoáº¡t Ä‘á»™ng")

        if st.button("ğŸ”„ Táº£i láº¡i Model", use_container_width=True):
            st.session_state.model_loaded = False
            st.session_state.chatbot = None
            st.cache_resource.clear()
            st.rerun()

    st.markdown("---")

    st.markdown("### ğŸ¨ Hiá»ƒn thá»‹")
    st.session_state.show_intent = st.checkbox("Hiá»ƒn thá»‹ Intent", value=st.session_state.show_intent)
    st.session_state.show_sources = st.checkbox("Hiá»ƒn thá»‹ nguá»“n tham kháº£o", value=st.session_state.show_sources)

    st.markdown("---")

    if st.session_state.model_loaded and st.session_state.data_stats:
        st.markdown("### ğŸ“Š Thá»‘ng kÃª")
        stats = st.session_state.data_stats
        st.markdown(f"""
        <div class="stats-card">
            <strong>ğŸ¥ Bá»‡nh:</strong> {stats.get('diseases', 0)}<br>
            <strong>ğŸ’¬ QA Pairs:</strong> {stats.get('qa_pairs', 0)}<br>
            <strong>ğŸ’¾ Embeddings:</strong> {stats.get('embeddings', 0)}<br>
            <strong>ğŸ“¦ QA file:</strong> {stats.get('qa_file', '')}<br>
            <strong>ğŸ“ Tin nháº¯n:</strong> {len(st.session_state.chat_history)}
        </div>
        """, unsafe_allow_html=True)

    st.markdown("---")

    st.markdown("### ğŸ“œ Quáº£n lÃ½ Chat")
    col1, col2 = st.columns(2)

    with col1:
        if st.button("ğŸ—‘ï¸ XÃ³a lá»‹ch sá»­", use_container_width=True):
            st.session_state.chat_history = []
            st.success("ÄÃ£ xÃ³a lá»‹ch sá»­!")
            st.rerun()

    with col2:
        chat_json = export_chat_history()
        if chat_json:
            st.download_button(
                label="ğŸ’¾ Export",
                data=chat_json,
                file_name=f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                use_container_width=True
            )

    st.markdown("---")

    st.markdown("### ğŸ’¡ CÃ¢u há»i máº«u")
    sample_questions = [
        "Hello",
        "Xin chÃ o",
        "Alo admin Æ¡i",
        "Nghá»‡ vÃ ng cÃ³ tÃ¡c dá»¥ng gÃ¬ vá»›i viÃªm dáº¡ dÃ y?",
        "Thuá»‘c Omeprazole dÃ¹ng nhÆ° tháº¿ nÃ o?",
        "Triá»‡u chá»©ng cá»§a viÃªm loÃ©t dáº¡ dÃ y?",
        "TÃ´i bá»‹ Ä‘au bá»¥ng, buá»“n nÃ´n lÃ  bá»‡nh gÃ¬?",
        "Tháº£o dÆ°á»£c nÃ o tá»‘t cho tiÃªu hÃ³a?"
    ]

    for i, question in enumerate(sample_questions):
        if st.button(f"ğŸ“ {question[:35]}...", key=f"sample_{i}", use_container_width=True):
            st.session_state.current_question = question
            st.rerun()

# ============================================================
# MAIN CONTENT
# ============================================================

st.markdown("""
<div class="main-header">
    <h1>ğŸ¥ Medical Chatbot Assistant</h1>
    <p>Trá»£ lÃ½ y táº¿ AI - TÆ° váº¥n thÃ´ng tin vá» bá»‡nh tiÃªu hÃ³a</p>
</div>
""", unsafe_allow_html=True)

st.markdown("""
<div class="warning-box">
    âš ï¸ <strong>LÆ°u Ã½ quan trá»ng:</strong> ThÃ´ng tin tá»« chatbot chá»‰ mang tÃ­nh tham kháº£o, 
    khÃ´ng thay tháº¿ cho cháº©n Ä‘oÃ¡n vÃ  tÆ° váº¥n y táº¿ trá»±c tiáº¿p tá»« bÃ¡c sÄ©. 
    Náº¿u cÃ³ triá»‡u chá»©ng nghiÃªm trá»ng, hÃ£y Ä‘áº¿n cÆ¡ sá»Ÿ y táº¿ ngay láº­p tá»©c.
</div>
""", unsafe_allow_html=True)

if not st.session_state.model_loaded:
    st.info("ğŸ‘ˆ Vui lÃ²ng nháº¥n nÃºt **'Khá»Ÿi Ä‘á»™ng Chatbot'** á»Ÿ sidebar Ä‘á»ƒ báº¯t Ä‘áº§u!")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown("### ğŸ©º Há»i vá» triá»‡u chá»©ng\nTÃ¬m hiá»ƒu cÃ¡c triá»‡u chá»©ng vÃ  dáº¥u hiá»‡u cá»§a bá»‡nh")
    with col2:
        st.markdown("### ğŸŒ¿ Tháº£o dÆ°á»£c & ÄÃ´ng y\nThÃ´ng tin vá» cÃ¡c loáº¡i tháº£o dÆ°á»£c vÃ  cÃ¡ch sá»­ dá»¥ng")
    with col3:
        st.markdown("### ğŸ’Š Thuá»‘c & TÆ°Æ¡ng tÃ¡c\nHÆ°á»›ng dáº«n sá»­ dá»¥ng thuá»‘c vÃ  tÆ°Æ¡ng tÃ¡c thuá»‘c")

else:
    # Display chat history
    for message in st.session_state.chat_history:
        with st.chat_message("user"):
            st.write(message["query"])

        with st.chat_message("assistant"):
            if st.session_state.show_intent and "intent" in message:
                intent = message["intent"]
                emoji = get_intent_emoji(intent)
                st.caption(f"{emoji} Intent: **{intent}**")

            st.markdown(message["response"])

            if st.session_state.show_sources and "retrieved_docs" in message:
                with st.expander("ğŸ“š Nguá»“n tham kháº£o"):
                    for i, doc in enumerate(message["retrieved_docs"], 1):
                        st.markdown(f"""
                        **Nguá»“n {i}:** {doc['qa'].get('disease', 'N/A')}  
                        **Äá»™ liÃªn quan:** {doc['score']:.2%}
                        """)

    # Chat input
    if 'current_question' in st.session_state:
        user_input = st.session_state.current_question
        del st.session_state.current_question
    else:
        user_input = st.chat_input("ğŸ’¬ Nháº­p cÃ¢u há»i cá»§a báº¡n...", key="chat_input")

    # Process user input
    if user_input:
        with st.chat_message("user"):
            st.write(user_input)

        with st.chat_message("assistant"):
            with st.spinner("ğŸ¤” Äang suy nghÄ©..."):
                try:
                    result = chat_with_bot(st.session_state.chatbot, user_input)

                    if st.session_state.show_intent:
                        intent = result["intent"]
                        emoji = get_intent_emoji(intent)
                        st.caption(f"{emoji} Intent: **{intent}**")

                    st.markdown(result["response"])

                    if st.session_state.show_sources and result.get("retrieved_docs"):
                        with st.expander("ğŸ“š Nguá»“n tham kháº£o"):
                            for i, doc in enumerate(result["retrieved_docs"], 1):
                                st.markdown(f"""
                                **Nguá»“n {i}:** {doc['qa'].get('disease', 'N/A')}  
                                **Äá»™ liÃªn quan:** {doc['score']:.2%}
                                """)

                    # Add to chat history
                    st.session_state.chat_history.append({
                        "query": user_input,
                        "intent": result["intent"],
                        "response": result["response"],
                        "retrieved_docs": result.get("retrieved_docs", []),
                        "timestamp": datetime.now().isoformat()
                    })

                except Exception as e:
                    st.error(f"âŒ Lá»—i: {str(e)}")

# ===== FOOTER =====
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 1rem;">
    <p>ğŸ¥ <strong>Medical Chatbot v1.0</strong> | Powered by OpenAI & RAG Technology</p>
    <p><small>âš ï¸ Chá»‰ dÃ¹ng Ä‘á»ƒ tham kháº£o - KhÃ´ng thay tháº¿ tÆ° váº¥n y táº¿ chuyÃªn nghiá»‡p</small></p>
</div>
""", unsafe_allow_html=True)
