# regenerate_embeddings.py - Regenerate embeddings cho Q&A má»›i
# Cháº¡y sau khi expand_qa_database.py

import json
import os
import pickle
import sys

# Fix Windows encoding
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

from dotenv import load_dotenv

load_dotenv()

def main():
    print("ğŸš€ Báº¯t Ä‘áº§u regenerate embeddings...\n")
    
    # Check OpenAI API key
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y OPENAI_API_KEY trong .env")
        return
    
    try:
        from openai import OpenAI
    except ImportError:
        print("âŒ Thiáº¿u thÆ° viá»‡n openai. Cháº¡y: pip install openai")
        return
    
    client = OpenAI(api_key=api_key)
    
    # Load data
    print("ğŸ“‹ Äang load data_loader.json...")
    with open('saved_model/data_loader.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    qa_bank = data.get('qa_bank_flat', [])
    docs = data.get('docs', [])
    
    print(f"   - Sá»‘ Q&A: {len(qa_bank)}")
    print(f"   - Sá»‘ docs: {len(docs)}")
    
    # Create embeddings for Q&A bank
    print("\nğŸ”„ Äang táº¡o embeddings cho Q&A bank...")
    qa_embeddings = []
    embedding_cache = {}
    
    for i, qa in enumerate(qa_bank):
        question = qa.get('question', '')
        answer = qa.get('answer', '')
        
        # Create combined text for embedding
        combined = f"CÃ¢u há»i: {question}\nTráº£ lá»i: {answer[:500]}"
        
        try:
            response = client.embeddings.create(
                input=[combined],
                model="text-embedding-3-small"
            )
            embedding = response.data[0].embedding
            
            qa_embeddings.append({
                'qa': qa,
                'embedding': embedding
            })
            
            # Cache the embedding
            embedding_cache[question] = embedding
            
            if (i + 1) % 50 == 0:
                print(f"   âœ… ÄÃ£ xá»­ lÃ½ {i + 1}/{len(qa_bank)} Q&A")
                
        except Exception as e:
            print(f"   âŒ Lá»—i embedding Q&A {i}: {e}")
            continue
    
    # Also create embeddings for docs
    print("\nğŸ”„ Äang táº¡o embeddings cho documents...")
    for i, doc in enumerate(docs):  # Process ALL docs
        text = doc.get('text', '')[:1000]  # Limit text length
        title = doc.get('title', '')
        
        combined = f"{title}\n{text}"
        
        try:
            response = client.embeddings.create(
                input=[combined],
                model="text-embedding-3-small"
            )
            embedding = response.data[0].embedding
            
            qa_embeddings.append({
                'qa': {
                    'question': title,
                    'answer': text,
                    'intent': doc.get('type', 'general'),
                    'disease': doc.get('metadata', {}).get('disease', '')
                },
                'embedding': embedding
            })
            
            embedding_cache[title] = embedding
            
            if (i + 1) % 50 == 0:
                print(f"   âœ… ÄÃ£ xá»­ lÃ½ {i + 1} documents")
                
        except Exception as e:
            print(f"   âŒ Lá»—i embedding doc {i}: {e}")
            continue
    
    # Save embeddings
    print("\nğŸ’¾ Äang lÆ°u embeddings...")
    
    # Backup old files (remove old backups first)
    if os.path.exists('saved_model/qa_embeddings_backup.pkl'):
        os.remove('saved_model/qa_embeddings_backup.pkl')
    if os.path.exists('saved_model/embedding_cache_backup.pkl'):
        os.remove('saved_model/embedding_cache_backup.pkl')
    if os.path.exists('saved_model/qa_embeddings.pkl'):
        os.rename('saved_model/qa_embeddings.pkl', 'saved_model/qa_embeddings_backup.pkl')
    if os.path.exists('saved_model/embedding_cache.pkl'):
        os.rename('saved_model/embedding_cache.pkl', 'saved_model/embedding_cache_backup.pkl')
    
    with open('saved_model/qa_embeddings.pkl', 'wb') as f:
        pickle.dump(qa_embeddings, f)
    
    with open('saved_model/embedding_cache.pkl', 'wb') as f:
        pickle.dump(embedding_cache, f)
    
    # Update metadata
    metadata = {
        'qa_count': len(qa_bank),
        'embedding_count': len(qa_embeddings),
        'model': 'text-embedding-3-small',
        'updated': True
    }
    
    with open('saved_model/model_metadata.json', 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    print(f"\n========================================")
    print(f"âœ… HoÃ n táº¥t regenerate embeddings!")
    print(f"   ğŸ“Š Q&A embeddings: {len(qa_embeddings)}")
    print(f"   ğŸ’¾ Cache size: {len(embedding_cache)}")
    print(f"========================================")
    print(f"\nâš ï¸ HÃ£y restart chatbot server Ä‘á»ƒ Ã¡p dá»¥ng thay Ä‘á»•i!")
    print(f"   cd chatbot/ThanhHai && python chatbot_api.py")

if __name__ == '__main__':
    main()
