{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24bdf1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/thanhhai/Projects1/python/venv/lib/python3.13/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.24.1 in /Users/thanhhai/Projects1/python/venv/lib/python3.13/site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Users/thanhhai/Projects1/python/venv/lib/python3.13/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /Users/thanhhai/Projects1/python/venv/lib/python3.13/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /Users/thanhhai/Projects1/python/venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.2.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U scikit-learn\n",
    "%pip install -U python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff97c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d855fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"Load v√† qu·∫£n l√Ω d·ªØ li·ªáu t·ª´ 6 file JSON\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.disease_names = {}\n",
    "        self.docs = []\n",
    "        self.metadata = {}\n",
    "        self.symptom_dict = {}\n",
    "        self.qa_bank_flat = []\n",
    "        self.qa_bank_full = []\n",
    "    \n",
    "    def load_from_strings(self, disease_json: str, docs_json: str, \n",
    "                         meta_json: str, symptom_json: str,\n",
    "                         qa_flat_json: str, qa_full_json: str):\n",
    "        self.disease_names = json.loads(disease_json)\n",
    "        self.docs = json.loads(docs_json) if isinstance(json.loads(docs_json), list) else [json.loads(docs_json)]\n",
    "        self.metadata = json.loads(meta_json)\n",
    "        self.symptom_dict = json.loads(symptom_json)\n",
    "        self.qa_bank_flat = json.loads(qa_flat_json) if isinstance(json.loads(qa_flat_json), list) else [json.loads(qa_flat_json)]\n",
    "        self.qa_bank_full = json.loads(qa_full_json) if isinstance(json.loads(qa_full_json), list) else [json.loads(qa_full_json)]\n",
    "        \n",
    "        print(f\"‚úì Loaded {len(self.disease_names)} diseases\")\n",
    "        print(f\"‚úì Loaded {len(self.docs)} documents\")\n",
    "        print(f\"‚úì Loaded {len(self.qa_bank_flat)} QA pairs\")\n",
    "        print(f\"‚úì Loaded {len(self.qa_bank_full)} disease entries\")\n",
    "\n",
    "data_loader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb352e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Embedding generator initialized\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingGenerator:\n",
    "    \"\"\"T·∫°o embeddings s·ª≠ d·ª•ng OpenAI\"\"\"\n",
    "    \n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        self.embedding_cache = {}\n",
    "    \n",
    "    def get_embedding(self, text: str, model=\"text-embedding-3-small\") -> List[float]:\n",
    "        \"\"\"L·∫•y embedding cho text\"\"\"\n",
    "        if text in self.embedding_cache:\n",
    "            return self.embedding_cache[text]\n",
    "        \n",
    "        text = text.replace(\"\\n\", \" \").strip()\n",
    "        response = self.client.embeddings.create(input=[text], model=model)\n",
    "        embedding = response.data[0].embedding\n",
    "        self.embedding_cache[text] = embedding\n",
    "        return embedding\n",
    "    \n",
    "    def compute_similarity(self, emb1: List[float], emb2: List[float]) -> float:\n",
    "        \"\"\"T√≠nh cosine similarity\"\"\"\n",
    "        return cosine_similarity([emb1], [emb2])[0][0]\n",
    "\n",
    "embedding_gen = EmbeddingGenerator(client)\n",
    "print(\"‚úì Embedding generator initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1279b72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Intent classifier initialized\n"
     ]
    }
   ],
   "source": [
    "class IntentClassifier:\n",
    "    \"\"\"Ph√¢n lo·∫°i intent c·ªßa user query\"\"\"\n",
    "    \n",
    "    INTENTS = {\n",
    "        \"symptoms\": [\"tri·ªáu ch·ª©ng\", \"d·∫•u hi·ªáu\", \"bi·ªÉu hi·ªán\", \"symptoms\", \"signs\"],\n",
    "        \"herb\": [\"th·∫£o d∆∞·ª£c\", \"ngh·ªá\", \"ƒë√¥ng y\", \"yhct\", \"herb\", \"herbal\"],\n",
    "        \"drug\": [\"thu·ªëc t√¢y\", \"thu·ªëc\", \"drug\", \"medicine\", \"medication\"],\n",
    "        \"interaction\": [\"t∆∞∆°ng t√°c\", \"d√πng chung\", \"k·∫øt h·ª£p\", \"interaction\", \"combine\"],\n",
    "        \"symptom_to_disease\": [\"t√¥i b·ªã\", \"t√¥i c√≥\", \"b·ªánh g√¨\", \"what disease\", \"I have\"],\n",
    "        \"general\": [\"l√† g√¨\", \"what is\", \"th√¥ng tin\", \"information\"]\n",
    "    }\n",
    "    \n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "    \n",
    "    def classify(self, query: str) -> str:\n",
    "        \"\"\"Ph√¢n lo·∫°i intent d·ª±a tr√™n keywords v√† LLM\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        for intent, keywords in self.INTENTS.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in query_lower:\n",
    "                    return intent\n",
    "        \n",
    "        return self._classify_with_llm(query)\n",
    "    \n",
    "    def _classify_with_llm(self, query: str) -> str:\n",
    "        \"\"\"S·ª≠ d·ª•ng LLM ƒë·ªÉ ph√¢n lo·∫°i intent ph·ª©c t·∫°p\"\"\"\n",
    "        prompt = f\"\"\"Ph√¢n lo·∫°i c√¢u h·ªèi sau v√†o m·ªôt trong c√°c intent:\n",
    "- symptoms: H·ªèi v·ªÅ tri·ªáu ch·ª©ng c·ªßa b·ªánh\n",
    "- herb: H·ªèi v·ªÅ th·∫£o d∆∞·ª£c, ƒë√¥ng y\n",
    "- drug: H·ªèi v·ªÅ thu·ªëc t√¢y y\n",
    "- interaction: H·ªèi v·ªÅ t∆∞∆°ng t√°c thu·ªëc-th·∫£o d∆∞·ª£c\n",
    "- symptom_to_disease: M√¥ t·∫£ tri·ªáu ch·ª©ng v√† h·ªèi b·ªánh g√¨\n",
    "- general: H·ªèi chung v·ªÅ b·ªánh\n",
    "\n",
    "C√¢u h·ªèi: \"{query}\"\n",
    "\n",
    "Tr·∫£ l·ªùi ƒê√öNG M·ªòT T·ª™ trong c√°c intent tr√™n:\"\"\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=10\n",
    "        )\n",
    "        \n",
    "        intent = response.choices[0].message.content.strip().lower()\n",
    "        return intent if intent in self.INTENTS.keys() else \"general\"\n",
    "\n",
    "intent_classifier = IntentClassifier(client)\n",
    "print(\"‚úì Intent classifier initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3970c033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì RAG retriever class defined\n"
     ]
    }
   ],
   "source": [
    "class RAGRetriever:\n",
    "    \n",
    "    def __init__(self, data_loader, embedding_gen):\n",
    "        self.data_loader = data_loader\n",
    "        self.embedding_gen = embedding_gen\n",
    "        self.qa_embeddings = []\n",
    "        self._build_index()\n",
    "    \n",
    "    def _build_index(self):\n",
    "        \"\"\"Build embedding index cho QA bank\"\"\"\n",
    "        print(\"Building QA embeddings index...\")\n",
    "        for qa in self.data_loader.qa_bank_flat:\n",
    "            questions_text = \" \".join(qa.get(\"questions\", []))\n",
    "            embedding = self.embedding_gen.get_embedding(questions_text)\n",
    "            self.qa_embeddings.append({\n",
    "                \"qa\": qa,\n",
    "                \"embedding\": embedding\n",
    "            })\n",
    "        print(f\"‚úì Built index with {len(self.qa_embeddings)} QA pairs\")\n",
    "    \n",
    "    def retrieve(self, query: str, intent: str, top_k: int = 3) -> List[Dict]:\n",
    "        \"\"\"Retrieve top-k relevant QA pairs\"\"\"\n",
    "        query_embedding = self.embedding_gen.get_embedding(query)\n",
    "        \n",
    "        scores = []\n",
    "        for item in self.qa_embeddings:\n",
    "            if intent != \"general\" and item[\"qa\"].get(\"intent\") != intent:\n",
    "                continue\n",
    "            \n",
    "            similarity = self.embedding_gen.compute_similarity(\n",
    "                query_embedding, \n",
    "                item[\"embedding\"]\n",
    "            )\n",
    "            scores.append((similarity, item[\"qa\"]))\n",
    "        \n",
    "        scores.sort(reverse=True, key=lambda x: x[0])\n",
    "        return [{\"score\": score, \"qa\": qa} for score, qa in scores[:top_k]]\n",
    "    \n",
    "    def get_disease_info(self, disease_name: str) -> Dict:\n",
    "        \"\"\"L·∫•y th√¥ng tin ƒë·∫ßy ƒë·ªß v·ªÅ b·ªánh\"\"\"\n",
    "        for disease_entry in self.data_loader.qa_bank_full:\n",
    "            disease = disease_entry.get(\"disease\", {})\n",
    "            if disease.get(\"label\") == disease_name or \\\n",
    "               disease.get(\"vi\") == disease_name or \\\n",
    "               disease.get(\"en\") == disease_name:\n",
    "                return disease_entry\n",
    "        return None\n",
    "\n",
    "rag_retriever = None  #\n",
    "print(\"‚úì RAG retriever class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "208b130c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Response generator class defined\n"
     ]
    }
   ],
   "source": [
    "class ResponseGenerator:\n",
    "    \"\"\"Generate c√¢u tr·∫£ l·ªùi s·ª≠ d·ª•ng LLM\"\"\"\n",
    "    \n",
    "    def __init__(self, client, data_loader):\n",
    "        self.client = client\n",
    "        self.data_loader = data_loader\n",
    "    \n",
    "    def generate(self, query: str, intent: str, retrieved_docs: List[Dict]) -> str:\n",
    "        \"\"\"Generate response t·ª´ retrieved documents\"\"\"\n",
    "        \n",
    "        if not retrieved_docs:\n",
    "            return self._generate_no_info_response(query)\n",
    "        \n",
    "        context = self._prepare_context(retrieved_docs)\n",
    "        \n",
    "        system_prompt = \"\"\"B·∫°n l√† tr·ª£ l√Ω y t·∫ø AI chuy√™n nghi·ªáp, tr·∫£ l·ªùi HO√ÄN TO√ÄN d·ª±a tr√™n d·ªØ li·ªáu c√≥ s·∫µn trong c∆° s·ªü d·ªØ li·ªáu (CSDL).\n",
    "\n",
    "QUY T·∫ÆC B·∫ÆT BU·ªòC:\n",
    "1. CH·ªà s·ª≠ d·ª•ng th√¥ng tin t·ª´ CSDL ƒë∆∞·ª£c cung c·∫•p\n",
    "2. KH√îNG b·ªï sung ki·∫øn th·ª©c y khoa b√™n ngo√†i\n",
    "3. KH√îNG ƒë∆∞a ra khuy·∫øn ngh·ªã ƒëi·ªÅu tr·ªã c·ª• th·ªÉ\n",
    "4. Lu√¥n nh·∫Øc nh·ªü: \"‚ö†Ô∏è Th√¥ng tin mang t√≠nh tham kh·∫£o, kh√¥ng thay th·∫ø ch·∫©n ƒëo√°n v√† t∆∞ v·∫•n y khoa tr·ª±c ti·∫øp\"\n",
    "5. N·∫øu CSDL kh√¥ng c√≥ th√¥ng tin, n√≥i r√µ \"CSDL ch∆∞a c√≥ th√¥ng tin v·ªÅ...\"\n",
    "6. Tr√≠ch d·∫´n ngu·ªìn t·ª´ CSDL khi c√≥\n",
    "7. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, r√µ r√†ng, c√≥ c·∫•u tr√∫c\n",
    "\n",
    "ƒê·ªäNH D·∫†NG TR·∫¢ L·ªúI:\n",
    "- S·ª≠ d·ª•ng bullet points khi li·ªát k√™\n",
    "- Highlight t·ª´ kh√≥a quan tr·ªçng b·∫±ng **bold**\n",
    "- Th√™m emoji ph√π h·ª£p ƒë·ªÉ d·ªÖ ƒë·ªçc\n",
    "\"\"\"\n",
    "        \n",
    "        user_prompt = f\"\"\"C√¢u h·ªèi: {query}\n",
    "\n",
    "Intent: {intent}\n",
    "\n",
    "Th√¥ng tin t·ª´ CSDL:\n",
    "{context}\n",
    "\n",
    "H√£y tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a HO√ÄN TO√ÄN tr√™n th√¥ng tin t·ª´ CSDL tr√™n.\"\"\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=1500\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def _prepare_context(self, retrieved_docs: List[Dict]) -> str:\n",
    "        \"\"\"Chu·∫©n b·ªã context t·ª´ retrieved documents\"\"\"\n",
    "        context_parts = []\n",
    "        \n",
    "        for i, doc in enumerate(retrieved_docs, 1):\n",
    "            qa = doc[\"qa\"]\n",
    "            score = doc[\"score\"]\n",
    "            \n",
    "            context_parts.append(f\"\"\"\n",
    "[T√†i li·ªáu {i}] (ƒê·ªô li√™n quan: {score:.2f})\n",
    "B·ªánh: {qa.get('disease', 'N/A')}\n",
    "Intent: {qa.get('intent', 'N/A')}\n",
    "C√¢u tr·∫£ l·ªùi t·ª´ CSDL:\n",
    "{qa.get('answer', 'N/A')}\n",
    "---\n",
    "\"\"\")\n",
    "        \n",
    "        return \"\\n\".join(context_parts)\n",
    "    \n",
    "    def _generate_no_info_response(self, query: str) -> str:\n",
    "        \"\"\"Generate response khi kh√¥ng t√¨m th·∫•y th√¥ng tin\"\"\"\n",
    "        return f\"\"\"Xin l·ªói, CSDL hi·ªán t·∫°i ch∆∞a c√≥ ƒë·ªß th√¥ng tin ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi: \"{query}\"\n",
    "\n",
    " G·ª£i √Ω:\n",
    "- Th·ª≠ di·ªÖn ƒë·∫°t c√¢u h·ªèi kh√°c ƒëi\n",
    "- Cung c·∫•p th√™m tri·ªáu ch·ª©ng c·ª• th·ªÉ\n",
    "- N√™u r√µ t√™n b·ªánh ho·∫∑c thu·ªëc b·∫°n mu·ªën h·ªèi\n",
    "\n",
    " N·∫øu b·∫°n c√≥ tri·ªáu ch·ª©ng nghi√™m tr·ªçng, h√£y ƒë·∫øn c∆° s·ªü y t·∫ø ƒë·ªÉ ƒë∆∞·ª£c thƒÉm kh√°m tr·ª±c ti·∫øp.\n",
    "\"\"\"\n",
    "\n",
    "response_generator = None  \n",
    "print(\"‚úì Response generator class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df1eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalChatbot:\n",
    "    \"\"\"Main chatbot class k·∫øt h·ª£p t·∫•t c·∫£ components\"\"\"\n",
    "    \n",
    "    def __init__(self, client, data_loader):\n",
    "        self.client = client\n",
    "        self.data_loader = data_loader\n",
    "        self.intent_classifier = IntentClassifier(client)\n",
    "        self.embedding_gen = EmbeddingGenerator(client)\n",
    "        self.rag_retriever = RAGRetriever(data_loader, self.embedding_gen)\n",
    "        self.response_generator = ResponseGenerator(client, data_loader)\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    def chat(self, user_query: str, verbose: bool = True) -> Dict:\n",
    "        \"\"\"Main chat function\"\"\"\n",
    "        \n",
    "        intent = self.intent_classifier.classify(user_query)\n",
    "        if verbose:\n",
    "            print(f\" Detected Intent: {intent}\")\n",
    "        \n",
    "        retrieved_docs = self.rag_retriever.retrieve(user_query, intent, top_k=3)\n",
    "        if verbose:\n",
    "            print(f\" Retrieved {len(retrieved_docs)} relevant documents\")\n",
    "            for i, doc in enumerate(retrieved_docs, 1):\n",
    "                print(f\"  {i}. {doc['qa'].get('disease', 'N/A')} (score: {doc['score']:.3f})\")\n",
    "        \n",
    "        response = self.response_generator.generate(user_query, intent, retrieved_docs)\n",
    "        \n",
    "        self.conversation_history.append({\n",
    "            \"query\": user_query,\n",
    "            \"intent\": intent,\n",
    "            \"response\": response,\n",
    "            \"retrieved_docs\": len(retrieved_docs)\n",
    "        })\n",
    "        \n",
    "        return {\n",
    "            \"query\": user_query,\n",
    "            \"intent\": intent,\n",
    "            \"response\": response,\n",
    "            \"retrieved_docs\": retrieved_docs\n",
    "        }\n",
    "    \n",
    "    def reset_conversation(self):\n",
    "        \"\"\"Reset conversation history\"\"\"\n",
    "        self.conversation_history = []\n",
    "        print(\"‚úì Conversation history reset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2fc58d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def load_json_files(data_folder: str = \".\"):\n",
    "    \"\"\"\n",
    "    Load t·∫•t c·∫£ 6 file JSON t·ª´ th∆∞ m·ª•c ch·ªâ ƒë·ªãnh\n",
    "    \n",
    "    Args:\n",
    "        data_folder: ƒê∆∞·ªùng d·∫´n t·ªõi th∆∞ m·ª•c ch·ª©a c√°c file JSON\n",
    "                    M·∫∑c ƒë·ªãnh l√† th∆∞ m·ª•c hi·ªán t·∫°i \".\"\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary ch·ª©a content c·ªßa 6 file d·∫°ng JSON string\n",
    "    \"\"\"\n",
    "    \n",
    "    file_mapping = {\n",
    "        'disease_names': 'kb_index_disease_name.json',\n",
    "        'docs': 'kb_index_docs.json',\n",
    "        'meta': 'kb_index_meta.json',\n",
    "        'symptom_dict': 'kb_index_symptom_dict.json',\n",
    "        'qa_flat': 'qa_bank_tieuhoa_flat.json',\n",
    "        'qa_full': 'qa_bank_tieuhoa.json'\n",
    "    }\n",
    "    \n",
    "    loaded_data = {}\n",
    "    \n",
    "    print(f\" Loading data from folder: {os.path.abspath(data_folder)}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for key, filename in file_mapping.items():\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        try:\n",
    "            if not os.path.exists(filepath):\n",
    "                print(f\" File not found: {filename}\")\n",
    "                print(f\"   Path: {filepath}\")\n",
    "                continue\n",
    "            \n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                loaded_data[key] = json.dumps(data, ensure_ascii=False)\n",
    "            \n",
    "            data_obj = json.loads(loaded_data[key])\n",
    "            if isinstance(data_obj, dict):\n",
    "                print(f\"‚úì {filename:40s} - {len(data_obj)} entries\")\n",
    "            elif isinstance(data_obj, list):\n",
    "                print(f\"‚úì {filename:40s} - {len(data_obj)} items\")\n",
    "            else:\n",
    "                print(f\"‚úì {filename:40s} - Loaded successfully\")\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\" JSON decode error in {filename}: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            print(f\" Error loading {filename}: {str(e)}\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Ki·ªÉm tra xem ƒë√£ load ƒë·ªß 6 file ch∆∞a\n",
    "    missing_files = set(file_mapping.keys()) - set(loaded_data.keys())\n",
    "    if missing_files:\n",
    "        print(f\"\\n  WARNING: Missing files: {missing_files}\")\n",
    "        print(\"Chatbot s·∫Ω ch·∫°y v·ªõi d·ªØ li·ªáu kh√¥ng ƒë·∫ßy ƒë·ªß!\")\n",
    "    else:\n",
    "        print(f\"\\n Successfully loaded all 6 JSON files!\")\n",
    "    \n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e953ae05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading data from folder: /Users/thanhhai/Projects1/python/grp/final\n",
      "======================================================================\n",
      "‚úì kb_index_disease_name.json               - 95 entries\n",
      "‚úì kb_index_docs.json                       - 548 items\n",
      "‚úì kb_index_meta.json                       - 6 entries\n",
      "‚úì kb_index_symptom_dict.json               - 95 entries\n",
      "‚úì qa_bank_tieuhoa_flat.json                - 55 items\n",
      "‚úì qa_bank_tieuhoa.json                     - 11 items\n",
      "======================================================================\n",
      "\n",
      " Successfully loaded all 6 JSON files!\n",
      "‚úì Loaded 95 diseases\n",
      "‚úì Loaded 548 documents\n",
      "‚úì Loaded 55 QA pairs\n",
      "‚úì Loaded 11 disease entries\n",
      "\n",
      "======================================================================\n",
      " DATA LOADING SUMMARY\n",
      "======================================================================\n",
      "Diseases: 95\n",
      "Documents: 548\n",
      "Symptoms: 95\n",
      "QA Flat: 55\n",
      "QA Full: 11\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    DATA_FOLDER = \".\" \n",
    "   \n",
    "    \n",
    "    json_data = load_json_files(DATA_FOLDER)\n",
    "    \n",
    "    data_loader.load_from_strings(\n",
    "        disease_json=json_data.get('disease_names', '{}'),\n",
    "        docs_json=json_data.get('docs', '[]'),\n",
    "        meta_json=json_data.get('meta', '{}'),\n",
    "        symptom_json=json_data.get('symptom_dict', '{}'),\n",
    "        qa_flat_json=json_data.get('qa_flat', '[]'),\n",
    "        qa_full_json=json_data.get('qa_full', '[]')\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" DATA LOADING SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Diseases: {len(data_loader.disease_names)}\")\n",
    "    print(f\"Documents: {len(data_loader.docs)}\")\n",
    "    print(f\"Symptoms: {len(data_loader.symptom_dict)}\")\n",
    "    print(f\"QA Flat: {len(data_loader.qa_bank_flat)}\")\n",
    "    print(f\"QA Full: {len(data_loader.qa_bank_full)}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n CRITICAL ERROR loading data: {str(e)}\")\n",
    "    print(\"\\n  Fallback to SAMPLE DATA for testing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a480efd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Initializing Medical Chatbot...\n",
      "Building QA embeddings index...\n",
      "‚úì Built index with 55 QA pairs\n",
      " Medical Chatbot initialized successfully!\n",
      "\n",
      " Quick Statistics:\n",
      "   - Total diseases in index: 95\n",
      "   - Total QA pairs: 55\n",
      "   - Total disease entries: 11\n",
      "   - Embedding cache size: 55\n",
      "\n",
      " Chatbot is ready to answer questions!\n",
      "   Run: test_chatbot() or interactive_chat()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== Initialize Chatbot =====\n",
    "print(\"\\n Initializing Medical Chatbot...\")\n",
    "chatbot = MedicalChatbot(client, data_loader)\n",
    "print(\" Medical Chatbot initialized successfully!\\n\")\n",
    "\n",
    "print(\" Quick Statistics:\")\n",
    "print(f\"   - Total diseases in index: {len(data_loader.disease_names)}\")\n",
    "print(f\"   - Total QA pairs: {len(data_loader.qa_bank_flat)}\")\n",
    "print(f\"   - Total disease entries: {len(data_loader.qa_bank_full)}\")\n",
    "print(f\"   - Embedding cache size: {len(chatbot.embedding_gen.embedding_cache)}\")\n",
    "print(\"\\n Chatbot is ready to answer questions!\")\n",
    "print(\"   Run: test_chatbot() or interactive_chat()\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9433c1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TESTING MEDICAL CHATBOT\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "TEST 1: d·ª± b√°o th·ªùi ti·∫øt h√¥m nay?\n",
      "======================================================================\n",
      " Detected Intent: general\n",
      " Retrieved 3 relevant documents\n",
      "  1. Diarrhea (Ti√™u ch·∫£y) (score: 0.241)\n",
      "  2. Diarrhea (Ti√™u ch·∫£y) (score: 0.233)\n",
      "  3. Hemorrhoids (Trƒ©) (score: 0.211)\n",
      "\n",
      "üí¨ Response:\n",
      "CSDL ch∆∞a c√≥ th√¥ng tin v·ªÅ **d·ª± b√°o th·ªùi ti·∫øt** h√¥m nay. ‚ö†Ô∏è Th√¥ng tin mang t√≠nh tham kh·∫£o, kh√¥ng thay th·∫ø ch·∫©n ƒëo√°n v√† t∆∞ v·∫•n y khoa tr·ª±c ti·∫øp.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "TEST 2: Ngh·ªá v√†ng c√≥ t√°c d·ª•ng g√¨ v·ªõi vi√™m d·∫° d√†y?\n",
      "======================================================================\n",
      " Detected Intent: herb\n",
      " Retrieved 3 relevant documents\n",
      "  1. Gastritis (Vi√™m d·∫° d√†y) (score: 0.568)\n",
      "  2. Gastroesophageal reflux ‚Äì GERD (Tr√†o ng∆∞·ª£c d·∫° d√†y th·ª±c qu·∫£n) (score: 0.456)\n",
      "  3. Hepatitis (Vi√™m gan) (score: 0.392)\n",
      "\n",
      "üí¨ Response:\n",
      "Ngh·ªá v√†ng c√≥ m·ªôt s·ªë t√°c d·ª•ng li√™n quan ƒë·∫øn **vi√™m d·∫° d√†y** (Gastritis) nh∆∞ sau:\n",
      "\n",
      "- **Th·∫£o d∆∞·ª£c ch√≠nh**: Ngh·ªá v√†ng\n",
      "- **C∆° ch·∫ø/ƒë√≠ch t√°c ƒë·ªông**:\n",
      "  - **Curcumin** trong ngh·ªá v√†ng c√≥ t√°c d·ª•ng **kh√°ng vi√™m**, **ch·ªëng oxy h√≥a**, v√† **b·∫£o v·ªá ni√™m m·∫°c** d·∫° d√†y.\n",
      "- **Con ƒë∆∞·ªùng t√°c ƒë·ªông**:\n",
      "  - Ngh·ªá v√†ng ·ª©c ch·∫ø c√°c y·∫øu t·ªë g√¢y vi√™m nh∆∞ **NF-Œ∫B**, **COX-2**, v√† **iNOS**.\n",
      "  - K√≠ch ho·∫°t **Nrf2‚ÄìHO-1** gi√∫p ch·ªëng oxy h√≥a v√† b·∫£o v·ªá gan ‚Äì d·∫° d√†y.\n",
      "- **D∆∞·ª£c ƒë·ªông h·ªçc**:\n",
      "  - Curcuminoid trong ngh·ªá v√†ng c√≥ kh·∫£ nƒÉng **h·∫•p thu r·∫•t th·∫•p**, nh∆∞ng kh·∫£ nƒÉng n√†y c√≥ th·ªÉ tƒÉng l√™n khi k·∫øt h·ª£p v·ªõi **piperine** ho·∫∑c nh≈© t∆∞∆°ng.\n",
      "  - Curcumin ∆∞a lipid v√† t√≠ch l≈©y trong m√¥, √≠t qua h√†ng r√†o m√°u n√£o (BBB).\n",
      "- **D∆∞·ª£c l·ª±c h·ªçc & hi·ªáu qu·∫£**:\n",
      "  - C√≥ t√°c d·ª•ng **kh√°ng vi√™m**, **ch·ªëng oxy h√≥a**.\n",
      "  - Li·ªÅu khuy·∫øn ngh·ªã t·ª´ **500 mg ƒë·∫øn 2 g/ng√†y** t√πy theo ch·∫ø ph·∫©m.\n",
      "  - C·∫ßn l∆∞u √Ω r·∫±ng li·ªÅu cao c√≥ th·ªÉ **tƒÉng nguy c∆° ch·∫£y m√°u** v√† c√≥ th·ªÉ **k√≠ch ·ª©ng d·∫° d√†y**.\n",
      "- **ƒê·ªôc t√≠nh/t√°c d·ª•ng ph·ª•**:\n",
      "  - Curcumin c√≥ **ƒë·ªôc t√≠nh c·∫•p th·∫•p**, nh∆∞ng c√≥ th·ªÉ g√¢y **k√≠ch ·ª©ng d·∫° d√†y** v√† hi·∫øm khi l√†m tƒÉng men gan.\n",
      "\n",
      "‚ö†Ô∏è Th√¥ng tin mang t√≠nh tham kh·∫£o, kh√¥ng thay th·∫ø ch·∫©n ƒëo√°n v√† t∆∞ v·∫•n y khoa tr·ª±c ti·∫øp.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "TEST 3: Thu·ªëc Omeprazole d√πng nh∆∞ th·∫ø n√†o?\n",
      "======================================================================\n",
      " Detected Intent: drug\n",
      " Retrieved 3 relevant documents\n",
      "  1. Gastritis (Vi√™m d·∫° d√†y) (score: 0.386)\n",
      "  2. Gastroesophageal reflux ‚Äì GERD (Tr√†o ng∆∞·ª£c d·∫° d√†y th·ª±c qu·∫£n) (score: 0.335)\n",
      "  3. Fatty liver (Gan nhi·ªÖm m·ª°) (score: 0.259)\n",
      "\n",
      "üí¨ Response:\n",
      "**Thu·ªëc Omeprazole** ƒë∆∞·ª£c s·ª≠ d·ª•ng ch·ªß y·∫øu trong ƒëi·ªÅu tr·ªã c√°c b·ªánh li√™n quan ƒë·∫øn d·∫° d√†y nh∆∞ **Gastritis (Vi√™m d·∫° d√†y)** v√† **Gastroesophageal reflux ‚Äì GERD (Tr√†o ng∆∞·ª£c d·∫° d√†y th·ª±c qu·∫£n)**. D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë th√¥ng tin chi ti·∫øt v·ªÅ c√°ch s·ª≠ d·ª•ng thu·ªëc n√†y:\n",
      "\n",
      "- **C∆° ch·∫ø t√°c ƒë·ªông**: \n",
      "  - Omeprazole ·ª©c ch·∫ø **b∆°m proton** (H‚Å∫/K‚Å∫-ATPase) t·∫°i t·∫ø b√†o th√†nh v·ªã, d·∫´n ƒë·∫øn **gi·∫£m ti·∫øt acid d·∫° d√†y**.\n",
      "\n",
      "- **D∆∞·ª£c ƒë·ªông h·ªçc**:\n",
      "  - Thu·ªëc c√≥ d·∫°ng **bao tan ru·ªôt** v√† ƒë∆∞·ª£c h·∫•p thu t·∫°i **ru·ªôt non**.\n",
      "  - Omeprazole b·ªã ph√° h·ªßy b·ªüi acid v√† g·∫Øn v·ªõi protein cao.\n",
      "  - Chuy·ªÉn h√≥a ch·ªß y·∫øu qua **gan** (CYP2C19/3A4) v√† th·∫£i tr·ª´ qua **th·∫≠n** v√† **m·∫≠t**.\n",
      "\n",
      "- **Li·ªÅu d√πng**:\n",
      "  - Th√¥ng th∆∞·ªùng, li·ªÅu s·ª≠ d·ª•ng l√† t·ª´ **20‚Äì40 mg/ng√†y**. Tuy nhi√™n, th√¥ng tin n√†y **kh√¥ng ph·∫£i khuy·∫øn ngh·ªã t·ª± d√πng thu·ªëc**.\n",
      "\n",
      "- **T√°c d·ª•ng ph·ª•**:\n",
      "  - C√≥ th·ªÉ g·∫∑p c√°c t√°c d·ª•ng ph·ª• nh∆∞ **ƒëau ƒë·∫ßu**, **ti√™u ch·∫£y**, v√† nguy c∆° thi·∫øu **Mg/B12**, c≈©ng nh∆∞ tƒÉng nguy c∆° **nhi·ªÖm tr√πng ti√™u h√≥a**.\n",
      "\n",
      "- **T∆∞∆°ng t√°c thu·ªëc**:\n",
      "  - Omeprazole c√≥ th·ªÉ l√†m gi·∫£m **h·∫•p thu s·∫Øt**, **canxi cacbonat**, v√† **n·∫•m men**. \n",
      "  - C√°c thu·ªëc antacid ho·∫∑c th·∫£o d∆∞·ª£c ki·ªÅm d·∫° d√†y c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn s·ª± h·∫•p thu c·ªßa Omeprazole.\n",
      "\n",
      "‚ö†Ô∏è Th√¥ng tin mang t√≠nh tham kh·∫£o, kh√¥ng thay th·∫ø ch·∫©n ƒëo√°n v√† t∆∞ v·∫•n y khoa tr·ª±c ti·∫øp.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "TEST 4: T√¥i b·ªã ƒëau b·ª•ng, bu·ªìn n√¥n, c√≥ th·ªÉ l√† b·ªánh g√¨?\n",
      "======================================================================\n",
      " Detected Intent: symptom_to_disease\n",
      " Retrieved 3 relevant documents\n",
      "  1. Nausea & vomiting (Bu·ªìn n√¥n v√† n√¥n) (score: 0.537)\n",
      "  2. Gastritis (Vi√™m d·∫° d√†y) (score: 0.443)\n",
      "  3. Irritable bowel syndrome ‚Äì IBS (H·ªôi ch·ª©ng ru·ªôt k√≠ch th√≠ch) (score: 0.441)\n",
      "\n",
      "üí¨ Response:\n",
      "D·ª±a tr√™n th√¥ng tin t·ª´ CSDL, c√°c tri·ªáu ch·ª©ng **ƒëau b·ª•ng** v√† **bu·ªìn n√¥n** c·ªßa b·∫°n c√≥ th·ªÉ li√™n quan ƒë·∫øn m·ªôt s·ªë b·ªánh l√Ω nh∆∞ sau:\n",
      "\n",
      "- **Nausea & vomiting (Bu·ªìn n√¥n v√† n√¥n)**:\n",
      "  - Tri·ªáu ch·ª©ng: C·∫£m gi√°c n√¥n nao ·ªü v√πng th∆∞·ª£ng v·ªã, tƒÉng d·∫ßn r·ªìi n√¥n, k√®m ch√≥ng m·∫∑t.\n",
      "  - C√¢u h·ªèi s√†ng l·ªçc:\n",
      "    - B·∫°n b·ªã bao l√¢u r·ªìi (gi·ªù/ng√†y/tu·∫ßn) v√† m·ª©c ƒë·ªô n·∫∑ng nh·∫π ra sao?\n",
      "    - B·∫°n c√≥ k√®m d·∫•u hi·ªáu n√†o kh√¥ng: n√¥n ra m√°u, ƒëi ngo√†i ph√¢n ƒëen, ƒëau b·ª•ng d·ªØ d·ªôi, s·ªët cao, v√†ng da-v√†ng m·∫Øt, s·ª•t c√¢n nhanh, m·∫•t n∆∞·ªõc, ho·∫∑c kh√≥ th·ªü/cho√°ng?\n",
      "\n",
      "- **Gastritis (Vi√™m d·∫° d√†y)**:\n",
      "  - Tri·ªáu ch·ª©ng: ƒêau √¢m ·ªâ ho·∫∑c b·ªèng r√°t v√πng th∆∞·ª£ng v·ªã, ƒë·∫ßy h∆°i, ·ª£ n√≥ng, bu·ªìn n√¥n, kh√≥ ti√™u sau ƒÉn.\n",
      "  - C√¢u h·ªèi s√†ng l·ªçc:\n",
      "    - B·∫°n b·ªã bao l√¢u r·ªìi (gi·ªù/ng√†y/tu·∫ßn) v√† m·ª©c ƒë·ªô n·∫∑ng nh·∫π ra sao?\n",
      "    - B·∫°n c√≥ k√®m d·∫•u hi·ªáu n√†o kh√¥ng: n√¥n ra m√°u, ƒëi ngo√†i ph√¢n ƒëen, ƒëau b·ª•ng d·ªØ d·ªôi, s·ªët cao, v√†ng da-v√†ng m·∫Øt, s·ª•t c√¢n nhanh, m·∫•t n∆∞·ªõc, ho·∫∑c kh√≥ th·ªü/cho√°ng?\n",
      "\n",
      "- **Irritable bowel syndrome ‚Äì IBS (H·ªôi ch·ª©ng ru·ªôt k√≠ch th√≠ch)**:\n",
      "  - Tri·ªáu ch·ª©ng: ƒêau b·ª•ng √¢m ·ªâ, ƒë·∫ßy h∆°i, s√¨nh b·ª•ng, r·ªëi lo·∫°n ƒëi ti√™u (l√∫c t√°o, l√∫c ti√™u ch·∫£y), gi·∫£m ƒëau sau khi ƒëi ngo√†i.\n",
      "  - C√¢u h·ªèi s√†ng l·ªçc:\n",
      "    - B·∫°n b·ªã bao l√¢u r·ªìi (gi·ªù/ng√†y/tu·∫ßn) v√† m·ª©c ƒë·ªô n·∫∑ng nh·∫π ra sao?\n",
      "    - B·∫°n c√≥ k√®m d·∫•u hi·ªáu n√†o kh√¥ng: n√¥n ra m√°u, ƒëi ngo√†i ph√¢n ƒëen, ƒëau b·ª•ng d·ªØ d·ªôi, s·ªët cao, v√†ng da-v√†ng m·∫Øt, s·ª•t c√¢n nhanh, m·∫•t n∆∞·ªõc, ho·∫∑c kh√≥ th·ªü/cho√°ng?\n",
      "\n",
      "‚ö†Ô∏è N·∫øu c√≥ d·∫•u hi·ªáu nguy hi·ªÉm (v√≠ d·ª•: n√¥n ra m√°u, ph√¢n ƒëen, ƒëau b·ª•ng d·ªØ d·ªôi, s·ªët cao, v√†ng da‚Ä¶), h√£y ƒëi kh√°m/c·∫•p c·ª©u.  \n",
      "‚ö†Ô∏è Th√¥ng tin mang t√≠nh tham kh·∫£o, kh√¥ng thay th·∫ø ch·∫©n ƒëo√°n v√† t∆∞ v·∫•n y khoa tr·ª±c ti·∫øp.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "TEST 5: Ma t√∫y h√∫t c√≥ ch·∫øt k\n",
      "======================================================================\n",
      " Detected Intent: general\n",
      " Retrieved 3 relevant documents\n",
      "  1. Hemorrhoids (Trƒ©) (score: 0.303)\n",
      "  2. Diarrhea (Ti√™u ch·∫£y) (score: 0.301)\n",
      "  3. Constipation (T√°o b√≥n) (score: 0.289)\n",
      "\n",
      "üí¨ Response:\n",
      "CSDL ch∆∞a c√≥ th√¥ng tin v·ªÅ vi·ªác ma t√∫y h√∫t c√≥ th·ªÉ g√¢y ch·∫øt ng∆∞·ªùi hay kh√¥ng. Tuy nhi√™n, vi·ªác s·ª≠ d·ª•ng ma t√∫y c√≥ th·ªÉ g√¢y ra nhi·ªÅu t√°c h·∫°i nghi√™m tr·ªçng ƒë·∫øn s·ª©c kh·ªèe, bao g·ªìm c·∫£ nguy c∆° t·ª≠ vong trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p.\n",
      "\n",
      "‚ö†Ô∏è Th√¥ng tin mang t√≠nh tham kh·∫£o, kh√¥ng thay th·∫ø ch·∫©n ƒëo√°n v√† t∆∞ v·∫•n y khoa tr·ª±c ti·∫øp.\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def test_chatbot():\n",
    "    \n",
    "    test_queries = [\n",
    "        \"d·ª± b√°o th·ªùi ti·∫øt h√¥m nay?\",\n",
    "        \"Ngh·ªá v√†ng c√≥ t√°c d·ª•ng g√¨ v·ªõi vi√™m d·∫° d√†y?\",\n",
    "        \"Thu·ªëc Omeprazole d√πng nh∆∞ th·∫ø n√†o?\",\n",
    "        \"T√¥i b·ªã ƒëau b·ª•ng, bu·ªìn n√¥n, c√≥ th·ªÉ l√† b·ªánh g√¨?\",\n",
    "        \"Ma t√∫y h√∫t c√≥ ch·∫øt k\"\n",
    "    ]\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"TESTING MEDICAL CHATBOT\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"TEST {i}: {query}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        result = chatbot.chat(query, verbose=True)\n",
    "        \n",
    "        print(f\"\\nüí¨ Response:\\n{result['response']}\")\n",
    "        print(f\"\\n{'-'*70}\")\n",
    "\n",
    "# Run tests\n",
    "test_chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "998da481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saving current chatbot model...\n",
      "\n",
      "======================================================================\n",
      " SAVING MEDICAL CHATBOT MODEL\n",
      "======================================================================\n",
      "\n",
      "[1/5] Saving Data Loader...\n",
      "   ‚úì Data Loader saved to data_loader.json\n",
      "\n",
      "[2/5] Saving Embedding Cache...\n",
      "   ‚úì Cached 60 embeddings\n",
      "\n",
      "[3/5] Saving QA Embeddings Index...\n",
      "   ‚úì Saved 55 QA embeddings\n",
      "\n",
      "[4/5] Saving Conversation History...\n",
      "   ‚úì Saved 5 conversations\n",
      "\n",
      "[5/5] Saving Model Metadata...\n",
      "   ‚úì Model metadata saved\n",
      "\n",
      "======================================================================\n",
      " MODEL SAVED SUCCESSFULLY!\n",
      "======================================================================\n",
      " Save location: /Users/thanhhai/Projects1/python/grp/final/saved_model\n",
      "\n",
      " Summary:\n",
      "   - Diseases: 95\n",
      "   - QA Pairs: 55\n",
      "   - Cached Embeddings: 60\n",
      "   - Conversation History: 5\n",
      "   - Saved at: 2025-12-23T22:30:57.481276\n",
      "======================================================================\n",
      "\n",
      "\n",
      " Testing model loading...\n",
      "\n",
      "======================================================================\n",
      "üìÇ LOADING MEDICAL CHATBOT MODEL\n",
      "======================================================================\n",
      "\n",
      "[1/5] Loading Data Loader...\n",
      "   ‚úì Loaded 95 diseases\n",
      "\n",
      "[2/5] Initializing Chatbot...\n",
      "Building QA embeddings index...\n",
      "‚úì Built index with 55 QA pairs\n",
      "   ‚úì Chatbot initialized\n",
      "\n",
      "[3/5] Loading Embedding Cache...\n",
      "   ‚úì Loaded 60 cached embeddings\n",
      "\n",
      "[4/5] Loading QA Embeddings Index...\n",
      "   ‚úì Loaded 55 QA embeddings\n",
      "\n",
      "[5/5] Loading Conversation History...\n",
      "   ‚úì Loaded 5 conversations\n",
      "\n",
      "======================================================================\n",
      " MODEL LOADED SUCCESSFULLY!\n",
      "======================================================================\n",
      " Model Info:\n",
      "   - Version: 1.0\n",
      "   - Saved at: 2025-12-23T22:30:57.481276\n",
      "   - Diseases: 95\n",
      "   - QA Pairs: 55\n",
      "======================================================================\n",
      "\n",
      "\n",
      " Testing loaded chatbot with a sample query...\n",
      "\n",
      " Query: Ngh·ªá v√†ng c√≥ t√°c d·ª•ng g√¨ v·ªõi vi√™m d·∫° d√†y?\n",
      "\n",
      " Response:\n",
      "Ngh·ªá v√†ng c√≥ m·ªôt s·ªë t√°c d·ª•ng li√™n quan ƒë·∫øn **vi√™m d·∫° d√†y** (Gastritis) nh∆∞ sau:\n",
      "\n",
      "- **Th·∫£o d∆∞·ª£c ch√≠nh**: Ngh·ªá v√†ng\n",
      "- **C∆° ch·∫ø t√°c ƒë·ªông**:\n",
      "  - **Curcumin** trong ngh·ªá v√†ng c√≥ t√°c d·ª•ng **kh√°ng vi√™m** v√† ...\n",
      "\n",
      " Model save/load test completed successfully!\n",
      "\n",
      " Usage:\n",
      "   - To save: save_chatbot_model(chatbot, data_loader)\n",
      "   - To load: loaded_chatbot = load_chatbot_model()\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def save_chatbot_model(chatbot, data_loader, save_dir=\"./saved_model\"):\n",
    "    \"\"\"\n",
    "    L∆∞u to√†n b·ªô chatbot model v√† data ƒë·ªÉ s·ª≠ d·ª•ng sau\n",
    "    \n",
    "    Args:\n",
    "        chatbot: MedicalChatbot instance\n",
    "        data_loader: DataLoader instance\n",
    "        save_dir: Th∆∞ m·ª•c l∆∞u model\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\" SAVING MEDICAL CHATBOT MODEL\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    print(\"\\n[1/5] Saving Data Loader...\")\n",
    "    data_dict = {\n",
    "        'disease_names': data_loader.disease_names,\n",
    "        'docs': data_loader.docs,\n",
    "        'metadata': data_loader.metadata,\n",
    "        'symptom_dict': data_loader.symptom_dict,\n",
    "        'qa_bank_flat': data_loader.qa_bank_flat,\n",
    "        'qa_bank_full': data_loader.qa_bank_full\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(save_dir, 'data_loader.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(data_dict, f, ensure_ascii=False, indent=2)\n",
    "    print(\"   ‚úì Data Loader saved to data_loader.json\")\n",
    "    \n",
    "    print(\"\\n[2/5] Saving Embedding Cache...\")\n",
    "    with open(os.path.join(save_dir, 'embedding_cache.pkl'), 'wb') as f:\n",
    "        pickle.dump(chatbot.embedding_gen.embedding_cache, f)\n",
    "    print(f\"   ‚úì Cached {len(chatbot.embedding_gen.embedding_cache)} embeddings\")\n",
    "    \n",
    "    print(\"\\n[3/5] Saving QA Embeddings Index...\")\n",
    "    with open(os.path.join(save_dir, 'qa_embeddings.pkl'), 'wb') as f:\n",
    "        pickle.dump(chatbot.rag_retriever.qa_embeddings, f)\n",
    "    print(f\"   ‚úì Saved {len(chatbot.rag_retriever.qa_embeddings)} QA embeddings\")\n",
    "    \n",
    "    print(\"\\n[4/5] Saving Conversation History...\")\n",
    "    with open(os.path.join(save_dir, 'conversation_history.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(chatbot.conversation_history, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"   ‚úì Saved {len(chatbot.conversation_history)} conversations\")\n",
    "    \n",
    "    print(\"\\n[5/5] Saving Model Metadata...\")\n",
    "    metadata = {\n",
    "        'saved_at': datetime.now().isoformat(),\n",
    "        'total_diseases': len(data_loader.disease_names),\n",
    "        'total_qa_pairs': len(data_loader.qa_bank_flat),\n",
    "        'total_embeddings': len(chatbot.embedding_gen.embedding_cache),\n",
    "        'model_version': '1.0',\n",
    "        'openai_model': 'gpt-4o-mini',\n",
    "        'embedding_model': 'text-embedding-3-small'\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(save_dir, 'model_metadata.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "    print(\"   ‚úì Model metadata saved\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\" MODEL SAVED SUCCESSFULLY!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\" Save location: {os.path.abspath(save_dir)}\")\n",
    "    print(f\"\\n Summary:\")\n",
    "    print(f\"   - Diseases: {metadata['total_diseases']}\")\n",
    "    print(f\"   - QA Pairs: {metadata['total_qa_pairs']}\")\n",
    "    print(f\"   - Cached Embeddings: {metadata['total_embeddings']}\")\n",
    "    print(f\"   - Conversation History: {len(chatbot.conversation_history)}\")\n",
    "    print(f\"   - Saved at: {metadata['saved_at']}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return save_dir\n",
    "\n",
    "\n",
    "def load_chatbot_model(save_dir=\"./saved_model\"):\n",
    "    \"\"\"\n",
    "    Load chatbot model ƒë√£ l∆∞u ƒë·ªÉ s·ª≠ d·ª•ng\n",
    "    \n",
    "    Args:\n",
    "        save_dir: Th∆∞ m·ª•c ch·ª©a model ƒë√£ l∆∞u\n",
    "        \n",
    "    Returns:\n",
    "        chatbot: MedicalChatbot instance ƒë√£ ƒë∆∞·ª£c load\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìÇ LOADING MEDICAL CHATBOT MODEL\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        raise FileNotFoundError(f\"Model directory not found: {save_dir}\")\n",
    "    \n",
    "    print(\"\\n[1/5] Loading Data Loader...\")\n",
    "    with open(os.path.join(save_dir, 'data_loader.json'), 'r', encoding='utf-8') as f:\n",
    "        data_dict = json.load(f)\n",
    "    \n",
    "    loaded_data_loader = DataLoader()\n",
    "    loaded_data_loader.disease_names = data_dict['disease_names']\n",
    "    loaded_data_loader.docs = data_dict['docs']\n",
    "    loaded_data_loader.metadata = data_dict['metadata']\n",
    "    loaded_data_loader.symptom_dict = data_dict['symptom_dict']\n",
    "    loaded_data_loader.qa_bank_flat = data_dict['qa_bank_flat']\n",
    "    loaded_data_loader.qa_bank_full = data_dict['qa_bank_full']\n",
    "    print(f\"   ‚úì Loaded {len(loaded_data_loader.disease_names)} diseases\")\n",
    "    \n",
    "    print(\"\\n[2/5] Initializing Chatbot...\")\n",
    "    loaded_chatbot = MedicalChatbot(client, loaded_data_loader)\n",
    "    print(\"   ‚úì Chatbot initialized\")\n",
    "    \n",
    "    print(\"\\n[3/5] Loading Embedding Cache...\")\n",
    "    with open(os.path.join(save_dir, 'embedding_cache.pkl'), 'rb') as f:\n",
    "        loaded_chatbot.embedding_gen.embedding_cache = pickle.load(f)\n",
    "    print(f\"   ‚úì Loaded {len(loaded_chatbot.embedding_gen.embedding_cache)} cached embeddings\")\n",
    "    \n",
    "    print(\"\\n[4/5] Loading QA Embeddings Index...\")\n",
    "    with open(os.path.join(save_dir, 'qa_embeddings.pkl'), 'rb') as f:\n",
    "        loaded_chatbot.rag_retriever.qa_embeddings = pickle.load(f)\n",
    "    print(f\"   ‚úì Loaded {len(loaded_chatbot.rag_retriever.qa_embeddings)} QA embeddings\")\n",
    "    \n",
    "    print(\"\\n[5/5] Loading Conversation History...\")\n",
    "    try:\n",
    "        with open(os.path.join(save_dir, 'conversation_history.json'), 'r', encoding='utf-8') as f:\n",
    "            loaded_chatbot.conversation_history = json.load(f)\n",
    "        print(f\"   ‚úì Loaded {len(loaded_chatbot.conversation_history)} conversations\")\n",
    "    except:\n",
    "        print(\"   ‚Ñπ  No conversation history found (starting fresh)\")\n",
    "    \n",
    "    with open(os.path.join(save_dir, 'model_metadata.json'), 'r', encoding='utf-8') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\" MODEL LOADED SUCCESSFULLY!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\" Model Info:\")\n",
    "    print(f\"   - Version: {metadata['model_version']}\")\n",
    "    print(f\"   - Saved at: {metadata['saved_at']}\")\n",
    "    print(f\"   - Diseases: {metadata['total_diseases']}\")\n",
    "    print(f\"   - QA Pairs: {metadata['total_qa_pairs']}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return loaded_chatbot\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n Saving current chatbot model...\")\n",
    "save_path = save_chatbot_model(chatbot, data_loader, save_dir=\"./saved_model\")\n",
    "\n",
    "print(\"\\n Testing model loading...\")\n",
    "loaded_chatbot = load_chatbot_model(save_dir=\"./saved_model\")\n",
    "\n",
    "# Test chatbot ƒë√£ load\n",
    "print(\"\\n Testing loaded chatbot with a sample query...\")\n",
    "test_query = \"Ngh·ªá v√†ng c√≥ t√°c d·ª•ng g√¨ v·ªõi vi√™m d·∫° d√†y?\"\n",
    "result = loaded_chatbot.chat(test_query, verbose=False)\n",
    "print(f\"\\n Query: {test_query}\")\n",
    "print(f\"\\n Response:\\n{result['response'][:200]}...\")\n",
    "\n",
    "print(\"\\n Model save/load test completed successfully!\")\n",
    "print(\"\\n Usage:\")\n",
    "print(\"   - To save: save_chatbot_model(chatbot, data_loader)\")\n",
    "print(\"   - To load: loaded_chatbot = load_chatbot_model()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f5806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_dir = \"./saved_model\"\n",
    "print(\"Abs path:\", os.path.abspath(save_dir))\n",
    "print(\"Exists:\", os.path.exists(save_dir))\n",
    "\n",
    "if os.path.exists(save_dir):\n",
    "    print(\"Files:\")\n",
    "    for fn in os.listdir(save_dir):\n",
    "        p = os.path.join(save_dir, fn)\n",
    "        print(\"-\", fn, \"|\", os.path.getsize(p), \"bytes\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
